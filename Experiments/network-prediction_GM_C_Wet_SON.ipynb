{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZeSZWtxITOh"
   },
   "source": [
    "# Field boundary mapping in small scale farming using multi-resolution satellite data\n",
    "\n",
    "The code was developed within a project funded by FAO, aiming at developing automatic workflows for mapping rice field boundaries in small-scale farming, using deep learning neural networks and advanced image processing. We conducted case studies in Cambodia and Vietnam, where rice paddy occupies a large portion of the agricultural area. We are facing two major challenges in the targeted research areas: (1) the lack of reference data, and (2) the fragmented agricultural areas characterized by very small fields (i.e., less than 1 ha). To overcome them, we used a convolutional deep learning U-Net network, able to achieve accurate segmentation result even with few training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16406,
     "status": "ok",
     "timestamp": 1647955885837,
     "user": {
      "displayName": "Fan Xinyan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhkJp63mq5E6WGkjbTtP8l2Ab_NUuAkRuzni9NliA=s64",
      "userId": "17970603424071756767"
     },
     "user_tz": -60
    },
    "id": "xFDIcczJKJEZ",
    "outputId": "2916e053-104b-4955-ae1a-9adef403d207"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import typing\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from skimage import exposure\n",
    "from osgeo import gdal\n",
    "\n",
    "# Install keras-unet library for python\n",
    "#%pip install git+https://github.com/karolzak/keras-unet\n",
    "\n",
    "\n",
    "# Define dataset directory on Colab\n",
    "# from google.colab import drive\n",
    "\n",
    "BASE_PATH = \"/home/jovyan/private/Agricultural_Field_Boundary\"\n",
    "INPUT_PATH = BASE_PATH + \"/Training_dataset/\"\n",
    "OUTPUT_PATH = BASE_PATH + \"/Networks/fine_tune_UNet5_Sentinel2/FAO_Cambodia_Unet\"\n",
    "EXPORT_OUTPUT_PATH = OUTPUT_PATH + \"/Export_Path_Cambodia_SON_GM_2020\"\n",
    "IMAGE_PATH = \"/Cambodia_SON_GM_2020\"\n",
    "LABEL_PATH = \"/Classified\"\n",
    "PREDICTION_PATH = BASE_PATH + \"/Training_dataset/\" + \"Cambodia\" + \"/Prediction_Cambodia_SON_GM_2020\"\n",
    "\n",
    "# INCLUDE_FOLDERS = [\"Flevoland\", \"Friesland\", \"Gelderland\", \"Limburg\", \"Overijssel\", \"Zeeland\", \"Zuid-Holland\", \"Vietnam\", \"Cambodia\"]\n",
    "INCLUDE_FOLDERS = [\"Cambodia\"]\n",
    "LEGEND = {\n",
    "    1: 'Other',\n",
    "    2: 'Field Boundary'\n",
    "}\n",
    "\n",
    "\n",
    "# To assess the accuracy you have to define the networks UUID and name here\n",
    "NETWORK_UUID = \"6c0f7e24-a85a-11ec-938c-02420a0001f1\"\n",
    "\n",
    "# Allowed Values:\n",
    "#   * FCNDK3\n",
    "#   * FCNDK4\n",
    "#   * FCNDK5\n",
    "#   * FCNDK6\n",
    "#   * UNet2\n",
    "#   * UNet3\n",
    "#   * UNet5\n",
    "NETWORK_NAME = \"UNet5\"\n",
    "\n",
    "\n",
    "# To compile the model, also the optimizer has to be defined\n",
    "NETWORK_OPTIMIZER = \"Adam\"\n",
    "\n",
    "# Ensure you use the same optimizer parameters as in the training run\n",
    "SGD_LEARNING_RATE = 0.0015\n",
    "SGD_MOMENTUM = 0.9\n",
    "ADAM_LEARNING_RATE = 0.001\n",
    "ADAM_BETA_1 = 0.9\n",
    "ADAM_BETA_2 = 0.999\n",
    "ADAM_EPSILON = 1e-06\n",
    "\n",
    "# Note: .ipynb_checkpoints are generated from the notebook interface\n",
    "# when removing/adding image samples manually. They should be deleted,\n",
    "# otherwise the Kernel will be died and forced to restart\n",
    "for folder in INCLUDE_FOLDERS:\n",
    "    original = INPUT_PATH + folder + IMAGE_PATH\n",
    "    classified = INPUT_PATH + folder + LABEL_PATH\n",
    "    if os.path.exists(f\"{original}/.ipynb_checkpoints\"):\n",
    "        shutil.rmtree(f\"{original}/.ipynb_checkpoints\")\n",
    "    if os.path.exists(f\"{classified}/.ipynb_checkpoints\"):\n",
    "        shutil.rmtree(f\"{classified}/.ipynb_checkpoints\")\n",
    "\n",
    "\n",
    "\n",
    "# Remark: All information in here could have been loaded from the training\n",
    "#         configuration file as well. However, we missed the chance to export\n",
    "#         the configuration as a machine readable type, e.g. JSON.\n",
    "#         Thus, we did not pass the config from the readme manually but set the\n",
    "#         parameters manually in here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 3367,
     "status": "ok",
     "timestamp": 1647955889199,
     "user": {
      "displayName": "Fan Xinyan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhkJp63mq5E6WGkjbTtP8l2Ab_NUuAkRuzni9NliA=s64",
      "userId": "17970603424071756767"
     },
     "user_tz": -60
    },
    "id": "sB6fZzP744dc"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################################################\n",
    "# Prerequisites for the network\n",
    "#\n",
    "# Includes a few helper functions which will be used to create and\n",
    "# evaluate the network, the training and the accuracy.\n",
    "# ################################################################\n",
    "\n",
    "import imp, h5py\n",
    "import pickle\n",
    "import uuid\n",
    "imp.reload(h5py)\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "\n",
    "# Tensorflow configuration\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "set_session(tf.compat.v1.Session(config=config))\n",
    "\n",
    "# ################################################################\n",
    "# Helper functions - import/export of network\n",
    "#\n",
    "# These two functions help to export the network and import it.\n",
    "# That allows to skip the training at a later stage.\n",
    "# ################################################################\n",
    "\n",
    "class ModelHistory:\n",
    "    \"\"\"Just a small container class to hold relevant information of a trained\n",
    "    model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, uuid, name, model, history, readme):\n",
    "        \"\"\"Create a new instance of this class\n",
    "        :param uuid: A unique identifier of the network\n",
    "        :param name: The networks name\n",
    "        :param model: The pretrained model\n",
    "        :param history: The training history of the model\n",
    "        :param readme: A small readme with a summary of training parameters\n",
    "        \"\"\"\n",
    "        self.uuid = uuid\n",
    "        self.name = name\n",
    "        self.model = model\n",
    "        self.history = history\n",
    "        self.readme = readme\n",
    "\n",
    "\n",
    "def get_file_names(uuid, name, is_export=True):\n",
    "    \"\"\"Generates three file names for the model, weights and history file and\n",
    "    the networks readme.\n",
    "\n",
    "    File name order of returned tuple:\n",
    "        * readme\n",
    "        * model\n",
    "        * weights\n",
    "        * history\n",
    "\n",
    "    :param uuid: Universal unique identifier of a trained network\n",
    "    :param name: The networks name\n",
    "    :return: Tuple with files in the order mentioned above\n",
    "    \"\"\"\n",
    "    if is_export:\n",
    "        base = f\"{EXPORT_OUTPUT_PATH}/{str(uuid)}-{name}\"\n",
    "    else:\n",
    "        base = f\"{EXPORT_OUTPUT_PATH}/{str(uuid)}-{name}\"\n",
    "\n",
    "\n",
    "    f_readme = f\"{base}-readme.txt\"\n",
    "    f_model = f\"{base}-model.h5\"\n",
    "    f_weights = f\"{base}-weights.h5\"\n",
    "    f_history = f\"{base}-history\"\n",
    "\n",
    "    return (f_readme, f_model, f_weights, f_history)\n",
    "\n",
    "\n",
    "def export_model(m: ModelHistory):\n",
    "    \"\"\"If a model is sufficiently trained, it can be exported. This allows to\n",
    "    simply save the models state and the training history. Whenever one want to\n",
    "    use the model the next time, the training can be skipped, since the trained\n",
    "    model can just be imported from files.\n",
    "\n",
    "    :param model_history: The trained model and history to be stored\n",
    "    \"\"\"\n",
    "    f_readme, f_model, f_weights, f_history = get_file_names(m.uuid,m.name,True)\n",
    "\n",
    "    # save readme\n",
    "    with open(f_readme, 'w') as f:\n",
    "        f.write(m.readme)\n",
    "    print(f\"Exported README: {f_readme}\")\n",
    "\n",
    "    # save models & weights\n",
    "    m.model.save(f_model)\n",
    "    print(f\"Exported model: {f_model}\")\n",
    "    m.model.save_weights(f_weights)\n",
    "    print(f\"Exported weights: {f_weights}\")\n",
    "\n",
    "    # save history\n",
    "    with open(f_history, \"wb\") as f:\n",
    "        pickle.dump(m.history, f)\n",
    "    print(f\"Exported history: {f_history}\")\n",
    "\n",
    "def import_model(uuid, name):\n",
    "    \"\"\"Previously exported models can be imported with this funciton.\n",
    "    :param uuid: The networks uuid\n",
    "    :param name: The networks name\n",
    "    :return: Instance of ModelHistory\n",
    "    \"\"\"\n",
    "    f_readme, f_model, f_weights, f_history = get_file_names(uuid, name,False)\n",
    "\n",
    "    # Load readme\n",
    "    with open(f_readme, 'r') as f:\n",
    "        readme = \"\".join(f.readlines())\n",
    "    print(f\"Imported README: {f_readme}\")\n",
    "\n",
    "    # Load model & weights\n",
    "    # model = tf.keras.models.load_model(f_model)\n",
    "    # Load model & weights, setting compile to 'False' when applying customer\n",
    "    # defined loss functions\n",
    "    model = tf.keras.models.load_model(f_model, compile=False)\n",
    "    print(f\"Imported model: {f_model}\")\n",
    "    model.load_weights(f_weights)\n",
    "    print(f\"Imported weights: {f_weights}\")\n",
    "\n",
    "    # Load history\n",
    "    with open(f_history, 'rb') as f:\n",
    "        history = pickle.load(f)\n",
    "    print(f\"Imported history: {f_history}\")\n",
    "\n",
    "    return ModelHistory(uuid, name, model, history, readme)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8101,
     "status": "ok",
     "timestamp": 1647955897680,
     "user": {
      "displayName": "Fan Xinyan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhkJp63mq5E6WGkjbTtP8l2Ab_NUuAkRuzni9NliA=s64",
      "userId": "17970603424071756767"
     },
     "user_tz": -60
    },
    "id": "pDAHrTgfawNZ",
    "outputId": "5ccf1038-084b-4d7f-dbb1-b1bda28d6480"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of image & label tiles: 2\n"
     ]
    }
   ],
   "source": [
    "# ################################################################\n",
    "# Loading input data\n",
    "#\n",
    "# Input data is loaded into two dictionaries: \n",
    "#\n",
    "# images: contains the 4-band images. The values are loaded as ints.\n",
    "# labels: contains 3D arrays in which each pixel is assigned with \n",
    "#         a label \"1\" = other and \"2\" = field boundary\n",
    "#\n",
    "# ################################################################\n",
    "\n",
    "\n",
    "def key_generator(file_name):\n",
    "    \"\"\"Generates the key of a file based on the file name. The resulting key is\n",
    "    a tuple of the province as string & the file number index as int,\n",
    "    e.g. (\"gelderland\", 29)\n",
    "    \"\"\"\n",
    "    file_name = file_name.lower()\n",
    "    file_name = file_name.replace(\"classified_\", \"\")\n",
    "    file_name = file_name.replace(\"original_\", \"\")\n",
    "    file_name = file_name.replace(\".tif\", \"\")\n",
    "    # TODO: Some images are named incorrectly\n",
    "    #       (e.g. no '_' between the province name and the image index)\n",
    "    (province, index) = tuple(file_name.split(\"_\"))\n",
    "    index = int(index)\n",
    "    return (province, index)\n",
    "\n",
    "def gtiff_to_array_geo(file_path):\n",
    "    \"\"\"Takes a file path and returns a tif file as a 3-dimensional numpy array, width x height x bands.\"\"\"\n",
    "    data = gdal.Open(file_path)\n",
    "    bands = [data.GetRasterBand(i+1).ReadAsArray() for i in range(data.RasterCount)]\n",
    "    return np.stack(bands, axis=2), data.GetGeoTransform(), data.GetProjection()\n",
    "\n",
    "def gtiff_to_array(file_path):\n",
    "    \"\"\"Takes a file path and returns a tif file as a 3-dimensional numpy array, width x height x bands.\"\"\"\n",
    "    data = gdal.Open(file_path)\n",
    "    bands = [data.GetRasterBand(i+1).ReadAsArray() for i in range(data.RasterCount)]\n",
    "    return np.stack(bands, axis=2)\n",
    "\n",
    "\n",
    "def transform_classification_image(input):\n",
    "    \"\"\"Takes the classification image input (in RGB format as 3D array) and \n",
    "    creates a 2D array out of this. The innermost array expects either values of\n",
    "    [0, 0, 0] of [255, 255, 255] since this is the colouring we assigned to the\n",
    "    classified images.\n",
    "\n",
    "    :param input: 3D input image (classification)\n",
    "    :return: 2D array image with labels 1 for 'other' and 2 for 'field_boundaries'\n",
    "    \"\"\"\n",
    "\n",
    "    # Out of the 3D input array it takes the \"max\" element out of the array\n",
    "    # This will either be 0 or 255. This function is just called to transform \n",
    "    # the 3D array to a 2D array.\n",
    "    result = np.reshape(np.max(input, axis=2), (input.shape[0], input.shape[1], 1))\n",
    "\n",
    "    # Now the array consists of pixels with values \"0\" or \"255\". We transform\n",
    "    # each value, that is larger than 0 (i.e. 255) and assign the label \"2\" to\n",
    "    # it. Each other element (i.e. 0) will get assigned the label \"1\".\n",
    "    result = np.where(result > 0, 2, 1)\n",
    "    return result\n",
    "\n",
    "# Dictionaries which contain the input data\n",
    "x_dict = {}\n",
    "y_dict = {}\n",
    "geoTrans = {}\n",
    "geoProj = {}\n",
    "\n",
    "# Iterate through defined folders and load all image data into the dictionaries\n",
    "# image_data and label_data. Images can be accessed with (<province>, <index>)\n",
    "for folder in INCLUDE_FOLDERS:\n",
    "    original = INPUT_PATH + folder + IMAGE_PATH\n",
    "    classified = INPUT_PATH + folder + LABEL_PATH\n",
    "    for f in os.listdir(original): \n",
    "        key = key_generator(f)\n",
    "        x_dict[key], geoTrans[key], geoProj[key] = gtiff_to_array_geo(original + \"/\" + f)\n",
    "\n",
    "print(f\"Total number of image & label tiles: {len(x_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1647955897959,
     "user": {
      "displayName": "Fan Xinyan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhkJp63mq5E6WGkjbTtP8l2Ab_NUuAkRuzni9NliA=s64",
      "userId": "17970603424071756767"
     },
     "user_tz": -60
    },
    "id": "9487wKIZKZpU",
    "outputId": "ca1982a9-ed2d-40d7-e8e2-1b6f47962f76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performed normalization of cambodia_14\n",
      "Performed normalization of cambodia_13\n"
     ]
    }
   ],
   "source": [
    "# ################################################################\n",
    "# Normalizing images\n",
    "#\n",
    "# Normalizing all input images into values in the interval [0, 1].\n",
    "# All bands are normalized seperately, which means, the min & max\n",
    "# of each band is calculated based on each band of the image data.\n",
    "# ################################################################\n",
    "\n",
    "def normalize_array_1(arr):\n",
    "    \"\"\"Takes a 3D array as input, iterates over the bands and normalizes those.\n",
    "\n",
    "    :param arr: input array (original image data) \n",
    "    :return: normalized data with values between 0 and 1\n",
    "    \"\"\"\n",
    "    arr_norm = np.zeros(arr.shape, dtype=np.float32)\n",
    "\n",
    "    for i in range(arr.shape[2]):\n",
    "        min = arr[:, :, i].min()\n",
    "        max = arr[:, :, i].max()\n",
    "        arr_norm[:,:,i] = (arr[:,:,i] - min) / (max - min)\n",
    "    return arr_norm\n",
    "\n",
    "def normalize_array_2(arr, minimum, maximum):\n",
    "\n",
    "    arr_norm = np.zeros(arr.shape, dtype=np.float32)\n",
    "\n",
    "    for i in range(arr.shape[2]):\n",
    "        arr_norm[:,:,i] = (arr[:,:,i] - minimum[i]) / (maximum[i] - minimum[i])\n",
    "    return arr_norm\n",
    "\n",
    "def normalize_array_3(arr, mean, sd):\n",
    "    \n",
    "    arr_norm = np.zeros(arr.shape, dtype=np.float32)\n",
    "\n",
    "    for i in range(arr.shape[2]):\n",
    "        arr_norm[:,:,i] = (arr[:,:,i] - mean[i]) / sd[i]\n",
    "    return arr_norm\n",
    "\n",
    "def get_feature_mins_maxs(images):\n",
    "    \"\"\"get the means and standard deviations per band for all image data\n",
    "    :param image: list of image data\n",
    "    :return: minima and maxima per band\n",
    "    \"\"\"\n",
    "    features_mins = []\n",
    "    features_maxs = []\n",
    "    arr = np.array(images)\n",
    "    for i in range(arr.shape[-1]):\n",
    "        features_mins.append(np.min(arr[:, :, :, i]))\n",
    "        features_maxs.append(np.max(arr[:, :, :, i]))\n",
    "    return np.array(features_mins), np.array(features_maxs)\n",
    "\n",
    "features_mins, features_maxs = get_feature_mins_maxs(list(x_dict.values()))\n",
    "for k, v in x_dict.items():\n",
    "    x_dict[k] = normalize_array_2(v, features_mins, features_maxs)\n",
    "    # x_dict[k] = normalize_array_1(v)\n",
    "    print(f\"Performed normalization of {k[0]}_{k[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 572,
     "status": "ok",
     "timestamp": 1647955898529,
     "user": {
      "displayName": "Fan Xinyan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhkJp63mq5E6WGkjbTtP8l2Ab_NUuAkRuzni9NliA=s64",
      "userId": "17970603424071756767"
     },
     "user_tz": -60
    },
    "id": "hzXD96NtZ3L1",
    "outputId": "faeca498-e5d6-470c-8595-1e6b4b36eb0e"
   },
   "outputs": [],
   "source": [
    "# ################################################################\n",
    "# Network builder functions\n",
    "#\n",
    "# Dynamic builder function for the FCN-DK (supposted from layer 2 to 6)\n",
    "# and unet (layer 1 to 5).\n",
    "# ################################################################\n",
    "\n",
    "#import model_segnet_Nbands\n",
    "\n",
    "from keras.layers import Activation, BatchNormalization, Convolution2D, LeakyReLU, Reshape, ZeroPadding2D\n",
    "from keras.models import Sequential\n",
    "# TODO: Consider which optimizer is the best\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "\n",
    "from keras_unet.models import satellite_unet\n",
    "\n",
    "def build_unet(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    bands: int,\n",
    "    labels: int,\n",
    "    layers: int = 2,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Create  a model of the popular U-Net network.\n",
    "\n",
    "    :param x: Number of rows (x-shape)\n",
    "    :param y: Number of columns (y-shape)\n",
    "    :param bands: Number of bands (z-shape)\n",
    "    :param lables: Number of labels to predict with the network\n",
    "    :param layers: Number of layers of the network\n",
    "    :return: Model of the corresponding U-Net network\n",
    "    \"\"\"\n",
    "    model = satellite_unet(\n",
    "        input_shape=(x, y, bands),\n",
    "        num_classes=labels,\n",
    "        output_activation=\"softmax\",\n",
    "        num_layers=layers,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def build_unet2(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    bands: int,\n",
    "    labels: int,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Wrapper function to build an UNet with 2 layers\n",
    "    \"\"\"\n",
    "    return build_unet(x, y, bands, labels, layers=2)\n",
    "    \n",
    "def build_unet3(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    bands: int,\n",
    "    labels: int,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Wrapper function to build an UNet with 3 layers\n",
    "    \"\"\"\n",
    "    return build_unet(x, y, bands, labels, layers=3)\n",
    "\n",
    "def build_unet5(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    bands: int,\n",
    "    labels: int,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Wrapper function to build an UNet with 5 layers\n",
    "    \"\"\"\n",
    "    return build_unet(x, y, bands, labels, layers=5)\n",
    "    \n",
    "\n",
    "\n",
    "def build_fcndk(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    prediction: int,\n",
    "    labels: int,\n",
    "    layers=4,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Build a new network model based on the configuration of the networks \n",
    "    FCNDK2, ..., FCNDK6. Specify the layers to use in the parameters.\n",
    "\n",
    "    :param x: Number of rows\n",
    "    :param y: Number of columns\n",
    "    :param bands: Number of bands in the input images\n",
    "    :param labels: Number of different labels to choose as the classification\n",
    "    :param layers: The number of FCNDK layers; Should be between 2 and 6 [default: 4]\n",
    "    :return: Model of the corresponding FCNDK network\n",
    "    \"\"\"\n",
    "    \"\"\"Model builder function for FCN-DK6.\"\"\"\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(ZeroPadding2D((2, 2), input_shape=(x, y, bands)))\n",
    "    model.add(Convolution2D(\n",
    "              filters=16,\n",
    "              kernel_size=(5, 5),\n",
    "              dilation_rate=(1, 1)))\n",
    "    model.add(BatchNormalization(axis=3))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "\n",
    "    if layers >= 2:\n",
    "        # FCNDK2\n",
    "        model.add(ZeroPadding2D((4, 4)))\n",
    "        model.add(Convolution2D(\n",
    "                filters=32,\n",
    "                kernel_size=(5, 5),\n",
    "                dilation_rate=(2, 2)\n",
    "        ))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "\n",
    "    if layers >= 3:\n",
    "        # FCNDK3\n",
    "        model.add(ZeroPadding2D((6, 6)))\n",
    "        model.add(Convolution2D(\n",
    "                filters=32,\n",
    "                kernel_size=(5, 5),\n",
    "                dilation_rate=(3, 3)\n",
    "        ))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "\n",
    "    if layers >= 4:\n",
    "        # FCNDK4\n",
    "        model.add(ZeroPadding2D((8, 8)))\n",
    "        model.add(Convolution2D(\n",
    "                filters=32,\n",
    "                kernel_size=(5, 5),\n",
    "                dilation_rate=(4, 4)\n",
    "        ))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "\n",
    "    if layers >= 5:\n",
    "        # FCNDK5\n",
    "        model.add(ZeroPadding2D((10, 10)))\n",
    "        model.add(Convolution2D(\n",
    "                filters=32,\n",
    "                kernel_size=(5, 5),\n",
    "                dilation_rate=(5, 5)\n",
    "        ))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "\n",
    "    if layers >= 6:\n",
    "        # FCNDK6\n",
    "        model.add(ZeroPadding2D((12, 12)))\n",
    "        model.add(Convolution2D(\n",
    "                filters=32,\n",
    "                kernel_size=(5, 5),\n",
    "                dilation_rate=(6, 6)\n",
    "        ))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Convolution2D(\n",
    "              filters=labels,\n",
    "              kernel_size=(1, 1)\n",
    "    ))\n",
    "\n",
    "    model.add(keras.layers.Activation(\n",
    "              activation=\"softmax\"\n",
    "    ))\n",
    "    return model\n",
    "\n",
    "def build_fcndk3(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    bands: int,\n",
    "    labels: int,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Wrapper function to build an FCNDK with 3 layers\n",
    "    \"\"\"\n",
    "    return build_fcndk(x, y, bands, labels, layers=3)\n",
    "    \n",
    "def build_fcndk4(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    bands: int,\n",
    "    labels: int,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Wrapper function to build an FCNDK with 4 layers\n",
    "    \"\"\"\n",
    "    return build_fcndk(x, y, bands, labels, layers=4)\n",
    "\n",
    "def build_fcndk5(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    bands: int,\n",
    "    labels: int,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Wrapper function to build an FCNDK with 5 layers\n",
    "    \"\"\"\n",
    "    return build_fcndk(x, y, bands, labels, layers=5)\n",
    "\n",
    "def build_fcndk6(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    bands: int,\n",
    "    labels: int,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Wrapper function to build an FCNDK with 6 layers\n",
    "    \"\"\"\n",
    "    return build_fcndk(x, y, bands, labels, layers=6)\n",
    "\n",
    "\n",
    "def build_network(name: str) -> typing.Callable:\n",
    "    \"\"\"Builds a new network, based on the networks name\n",
    "    :param name: The networks name\n",
    "    :return: The builder function of the corresponding network.\n",
    "    \"\"\"\n",
    "    if name.lower() == \"fcndk3\":\n",
    "        return build_fcndk3\n",
    "    elif name.lower() == \"fcndk4\":\n",
    "        return build_fcndk4\n",
    "    elif name.lower() == \"fcndk5\":\n",
    "        return build_fcndk5\n",
    "    elif name.lower() == \"fcndk6\":\n",
    "        return build_fcndk6\n",
    "    elif name.lower() == \"unet2\":\n",
    "        return build_unet2\n",
    "    elif name.lower() == \"unet3\":\n",
    "        return build_unet3\n",
    "    elif name.lower() == \"unet5\":\n",
    "        return build_unet5\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7291,
     "status": "ok",
     "timestamp": 1647955905818,
     "user": {
      "displayName": "Fan Xinyan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhkJp63mq5E6WGkjbTtP8l2Ab_NUuAkRuzni9NliA=s64",
      "userId": "17970603424071756767"
     },
     "user_tz": -60
    },
    "id": "Qba8oSlkZ3Lu",
    "outputId": "027aeb14-e1bb-44dc-af2d-9afc1648a4d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported README: /home/jovyan/private/Agricultural_Field_Boundary/Networks/fine_tune_UNet5_Sentinel2/FAO_Cambodia_Unet/Export_Path_Cambodia_SON_GM_2020/6c0f7e24-a85a-11ec-938c-02420a0001f1-UNet5-readme.txt\n",
      "Imported model: /home/jovyan/private/Agricultural_Field_Boundary/Networks/fine_tune_UNet5_Sentinel2/FAO_Cambodia_Unet/Export_Path_Cambodia_SON_GM_2020/6c0f7e24-a85a-11ec-938c-02420a0001f1-UNet5-model.h5\n",
      "Imported weights: /home/jovyan/private/Agricultural_Field_Boundary/Networks/fine_tune_UNet5_Sentinel2/FAO_Cambodia_Unet/Export_Path_Cambodia_SON_GM_2020/6c0f7e24-a85a-11ec-938c-02420a0001f1-UNet5-weights.h5\n",
      "Imported history: /home/jovyan/private/Agricultural_Field_Boundary/Networks/fine_tune_UNet5_Sentinel2/FAO_Cambodia_Unet/Export_Path_Cambodia_SON_GM_2020/6c0f7e24-a85a-11ec-938c-02420a0001f1-UNet5-history\n",
      "Load existing network: 6c0f7e24-a85a-11ec-938c-02420a0001f1 UNet5\n",
      "\n",
      "Training configuration\n",
      "================================\n",
      "Network\n",
      "    UUID:               6c0f7e24-a85a-11ec-938c-02420a0001f1\n",
      "    Name:               UNet5\n",
      "    Optimizer:          Adam\n",
      "\n",
      "Parameters\n",
      "    Bands:              4\n",
      "    Classes:            2\n",
      "    Epochs:             600\n",
      "    Batch Size:         8\n",
      "\n",
      "Optimizer (Adam)\n",
      "    Learning Rate:      0.0015\n",
      "    Beta 1:             0.9\n",
      "    Beta 2:             0.999\n",
      "    Epsilon:            1e-06\n",
      "    \n",
      "Execution summary\n",
      "    Patches:            760\n",
      "    Validation Split:   0.05\n",
      "    Resolution (px):    256x256\n",
      "    Bands:              4\n",
      "    Classes:            1\n",
      "\n",
      "Training Set:\n",
      "    (flevoland, 21)\n",
      "    (overijssel, 14)\n",
      "    (zeeland, 76)\n",
      "    (overijssel, 32)\n",
      "    (friesland, 178)\n",
      "    (friesland, 123)\n",
      "    (limburg, 110)\n",
      "    (zeeland, 51)\n",
      "    (zeeland, 5)\n",
      "    (zeeland, 23)\n",
      "    (overijssel, 98)\n",
      "    (overijssel, 43)\n",
      "    (friesland, 180)\n",
      "    (friesland, 134)\n",
      "    (zeeland, 62)\n",
      "    (zeeland, 7)\n",
      "    (overijssel, 18)\n",
      "    (limburg, 96)\n",
      "    (overijssel, 45)\n",
      "    (flevoland, 64)\n",
      "    (friesland, 136)\n",
      "    (overijssel, 2)\n",
      "    (zeeland, 64)\n",
      "    (zeeland, 9)\n",
      "    (overijssel, 20)\n",
      "    (zeeland, 18)\n",
      "    (overijssel, 29)\n",
      "    (friesland, 175)\n",
      "    (flevoland, 66)\n",
      "    (zeeland, 48)\n",
      "    (gelderland, 29)\n",
      "    (friesland, 150)\n",
      "    (limburg, 82)\n",
      "    (overijssel, 31)\n",
      "    (flevoland, 50)\n",
      "    (friesland, 177)\n",
      "    (zeeland, 32)\n",
      "    (zeeland, 50)\n",
      "    (overijssel, 6)\n",
      "    (overijssel, 70)\n",
      "    (overijssel, 15)\n",
      "    (flevoland, 34)\n",
      "    (overijssel, 33)\n",
      "    (friesland, 161)\n",
      "    (flevoland, 52)\n",
      "    (friesland, 179)\n",
      "    (zeeland, 34)\n",
      "    (flevoland, 36)\n",
      "    (zeeland, 36)\n",
      "    (overijssel, 56)\n",
      "    (overijssel, 1)\n",
      "    (zeeland, 63)\n",
      "    (friesland, 138)\n",
      "    (flevoland, 20)\n",
      "    (overijssel, 19)\n",
      "    (flevoland, 93)\n",
      "    (zeeland, 20)\n",
      "    (zeeland, 47)\n",
      "    (overijssel, 58)\n",
      "    (friesland, 195)\n",
      "    (flevoland, 22)\n",
      "    (zeeland, 22)\n",
      "    (zeeland, 31)\n",
      "    (overijssel, 60)\n",
      "    (zuid-holland, 114)\n",
      "    (gelderland, 30)\n",
      "    (flevoland, 79)\n",
      "    (zeeland, 6)\n",
      "    (zeeland, 33)\n",
      "    (overijssel, 44)\n",
      "    (overijssel, 7)\n",
      "    (overijssel, 71)\n",
      "    (zeeland, 8)\n",
      "    (friesland, 162)\n",
      "    (flevoland, 108)\n",
      "    (zeeland, 35)\n",
      "    (overijssel, 46)\n",
      "    (flevoland, 65)\n",
      "    (friesland, 137)\n",
      "    (flevoland, 37)\n",
      "    (overijssel, 21)\n",
      "    (zeeland, 19)\n",
      "    (overijssel, 30)\n",
      "    (zeeland, 37)\n",
      "    (overijssel, 57)\n",
      "Test Set:\n",
      "    (friesland, 148)\n",
      "    (zeeland, 3)\n",
      "    (overijssel, 17)\n",
      "    (friesland, 151)\n",
      "    (flevoland, 94)\n",
      "    (overijssel, 84)\n",
      "    (zeeland, 21)\n",
      "    (friesland, 163)\n",
      "    (zeeland, 24)\n",
      "    (friesland, 166)\n",
      "    (flevoland, 51)\n",
      "    (overijssel, 35)\n",
      "    (limburg, 165)\n",
      "    (zuid-holland, 101)\n",
      "    (overijssel, 59)\n",
      "    (friesland, 135)\n",
      "    (overijssel, 4)\n",
      "    (overijssel, 74)\n",
      "    (overijssel, 16)\n",
      "    (friesland, 165)\n",
      "    (overijssel, 34)\n",
      "    (zuid-holland, 100)\n",
      "    (overijssel, 3)\n",
      "    (flevoland, 80)\n",
      "    (zeeland, 4)\n",
      "    (gelderland, 37)\n",
      "    (friesland, 149)\n",
      "    (zeeland, 10)\n",
      "    (friesland, 152)\n",
      "    (flevoland, 95)\n",
      "    (zeeland, 77)\n",
      "    (friesland, 164)\n",
      "    (flevoland, 107)\n",
      "    (limburg, 166)\n",
      "    (friesland, 176)\n",
      "    (zeeland, 49)\n",
      "    (overijssel, 5)\n"
     ]
    }
   ],
   "source": [
    "# ################################################################\n",
    "# Creating network\n",
    "#\n",
    "# In this code block, the network configuration is loaded properly\n",
    "# and the corresponding builder function is called.\n",
    "# ################################################################\n",
    "\n",
    "NUMBER_BANDS = 4\n",
    "NUMBER_CLASSES = 2\n",
    "NUMBER_EPOCHS = 10\n",
    "NUMBER_BATCHES = 64\n",
    "VALIDATION_SPLIT = 0.02\n",
    "\n",
    "model_builder = build_network(NETWORK_NAME)\n",
    "\n",
    "# Optimizer (actually  not required anymore, but code legacy requires it.)\n",
    "if NETWORK_OPTIMIZER == \"Adam\":\n",
    "    OPTIMIZER = tf.keras.optimizers.Adam(\n",
    "        learning_rate=ADAM_LEARNING_RATE,\n",
    "        beta_1=ADAM_BETA_1, \n",
    "        beta_2=ADAM_BETA_2, \n",
    "        epsilon=ADAM_EPSILON\n",
    "    )\n",
    "elif NETWORK_OPTIMIZER == \"SGD\":\n",
    "    OPTIMIZER = tf.keras.optimizers.SGD(\n",
    "        learning_rate=SGD_LEARNING_RATE, \n",
    "        momentum=SGD_MOMENTUM\n",
    "    )\n",
    "\n",
    "# Load existing network from files\n",
    "m = import_model(NETWORK_UUID, NETWORK_NAME)\n",
    "readme = m.readme\n",
    "model = m.model\n",
    "history = m.history\n",
    "print(f\"Load existing network: {NETWORK_UUID} {NETWORK_NAME}\")\n",
    "\n",
    "# Print configuration README before (possible) training\n",
    "print(readme)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647955905819,
     "user": {
      "displayName": "Fan Xinyan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhkJp63mq5E6WGkjbTtP8l2Ab_NUuAkRuzni9NliA=s64",
      "userId": "17970603424071756767"
     },
     "user_tz": -60
    },
    "id": "yaknOjT38cZS"
   },
   "outputs": [],
   "source": [
    "# ################################################################\n",
    "# Predictions & export\n",
    "#\n",
    "# Here, the network is fed with the given input files. Resulting\n",
    "# predictions are exported as TIF files.\n",
    "# ################################################################\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "\n",
    "def evaluate_predictions(\n",
    "    input: np.ndarray,\n",
    "    nc: int,\n",
    "    f_weights: str,\n",
    "    optimizer: tf.keras.optimizers.Optimizer,\n",
    "    model_builder: typing.Callable,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Takes an input image, patches it into smaller patches and feeds the FCN\n",
    "    with each of the patches. The output samples are patches of the predicted\n",
    "    classification. These patches are combined into one large image, that can\n",
    "    be compared with the classified image of the corresponding input data.\n",
    "\n",
    "    :param input: test image to evaluate\n",
    "    :param nc: Number of classes/labels\n",
    "    :param f_weights: File path to the corresponding weights file\n",
    "    :param optimizer: Optimizer for the network\n",
    "    :param model_build: method to create the model\n",
    "    :return: 2D ndarray of the predicted labels\n",
    "    \"\"\"\n",
    "    x, y, bands = input.shape\n",
    "\n",
    "    # Build model and load model weights\n",
    "    model = model_builder(x, y, bands, nc)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics='accuracy')\n",
    "    #model.compile(optimizer=OPTIMIZER, loss=focal_tversky_loss, metrics='accuracy')\n",
    "    model.load_weights(f_weights)\n",
    "\n",
    "    # Predict field boundaries in network\n",
    "    # Increase dimension to perform batch prediction\n",
    "    input = np.expand_dims(input, 0)\n",
    "    prediction = model.predict(input)[0]\n",
    "    # Map highest score onto label\n",
    "    # prediction = np.argmax(prediction, axis=2) + 1\n",
    "    return prediction[:,:,1]\n",
    "\n",
    "def export_array(labels: np.ndarray, filename: str):\n",
    "    \"\"\"Maps labels onto the colors black & white and exports the resulting image\n",
    "    as a file with the given file.\n",
    "\n",
    "    :param labels: 2D array of labels per pixel\n",
    "    :param filename: File name of the new file\n",
    "    \"\"\"\n",
    "    x, y = labels.shape\n",
    "\n",
    "    img = np.zeros((x, y, 3), dtype=np.uint8)\n",
    "\n",
    "    for i in range(img.shape[2]):\n",
    "        img[:, :, i] = np.where(labels[:, :] == 2, 255, 0)\n",
    "\n",
    "    Image.fromarray(img).save(filename)\n",
    "    #Image.fromarray(img).save()\n",
    "    #pyplot.imsave(filename, Image.fromarray(img))\n",
    "\n",
    "def export_geotiff(labels: np.ndarray, geoTrans, geoProj, filename: str):\n",
    "    \"\"\"Maps labels onto the colors black & white and exports the resulting image\n",
    "    as a file with the given file.\n",
    "\n",
    "    :param labels: 2D array of labels per pixel\n",
    "    :param filename: File name of the new file\n",
    "    \"\"\"\n",
    "    x, y = labels.shape\n",
    "    # labels[:, :] = np.where(labels[:, :] == 2, 65535, 0)\n",
    "    labels[:, :] *= 65535\n",
    "    # import matplotlib.pylab as plt\n",
    "    # plt.hist(labels.reshape(x*y)); plt.show()\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    outData = driver.Create(filename, x, y, 3, gdal.GDT_UInt16)\n",
    "\n",
    "    # Write metadata\n",
    "    outData.SetGeoTransform(geoTrans)\n",
    "    outData.SetProjection(geoProj)\n",
    "\n",
    "    # Write raster data sets\n",
    "    for i in range(3):\n",
    "      outData.GetRasterBand(i+1).WriteArray(labels)\n",
    "    outData.FlushCache()\n",
    "    outData = None     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35790,
     "status": "ok",
     "timestamp": 1647955941605,
     "user": {
      "displayName": "Fan Xinyan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhkJp63mq5E6WGkjbTtP8l2Ab_NUuAkRuzni9NliA=s64",
      "userId": "17970603424071756767"
     },
     "user_tz": -60
    },
    "id": "iqWLGyUIJjm4",
    "outputId": "b8b6119d-5d95-4d8e-e66c-d46f2ddfcb88"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 14:47:04.562394: W tensorflow/core/common_runtime/bfc_allocator.cc:360] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported prediction /home/jovyan/private/Agricultural_Field_Boundary/Training_dataset/Cambodia/Prediction_Cambodia_SON_GM_2020Cambodia/Prediction_UNet5/prediction_cambodia_14.tif\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Exported prediction /home/jovyan/private/Agricultural_Field_Boundary/Training_dataset/Cambodia/Prediction_Cambodia_SON_GM_2020Cambodia/Prediction_UNet5/prediction_cambodia_13.tif\n"
     ]
    }
   ],
   "source": [
    "# ################################################################\n",
    "# Predict images and store as TIF\n",
    "#\n",
    "# This code block will iterate through the included folders and\n",
    "# performs predictions on the satellite image tiles. The resulting\n",
    "# images are mapped onto black & white and then exported as TIF\n",
    "# files\n",
    "# ################################################################\n",
    "\n",
    "import pathlib\n",
    "\n",
    "\n",
    "keys_per_province = dict()\n",
    "\n",
    "for f in INCLUDE_FOLDERS:\n",
    "    keys_per_province[f] = [k for k in x_dict.keys() if k[0].lower() == f.lower()]\n",
    "\n",
    "for f, keys in keys_per_province.items():\n",
    "    for k in keys:\n",
    "        x = x_dict[k]\n",
    "\n",
    "        (_, _, f_weights, _) = get_file_names(NETWORK_UUID, NETWORK_NAME)\n",
    "\n",
    "        try:\n",
    "            img = evaluate_predictions(\n",
    "                x,\n",
    "                NUMBER_CLASSES,\n",
    "                f_weights,\n",
    "                OPTIMIZER,\n",
    "                model_builder,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to predict image of size {x.shape[0]}x{x.shape[1]}\")\n",
    "            continue\n",
    "\n",
    "        # Build directory name\n",
    "        fname = PREDICTION_PATH\n",
    "        fname += f\"{f}/\"\n",
    "        fname += f\"Prediction_{NETWORK_NAME}/\"\n",
    "\n",
    "        # Create directory\n",
    "        pathlib.Path(fname).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # build filename\n",
    "        fname += f\"prediction_{k[0]}_{k[1]}\"\n",
    "        fname += \".tif\"\n",
    "\n",
    "        # export_array(img, fname)\n",
    "        export_geotiff(img, geoTrans[k],geoProj[k],fname)\n",
    "        print(f\"Exported prediction {fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file size is 768, 768\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 768, 768\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 768, 768\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 768, 768\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 768, 768\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 768, 768\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 768, 768\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 768, 768\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 768, 768\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Patches saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Define the patch size and input file path\n",
    "patch_width = 256\n",
    "patch_height = 256\n",
    "input_file = \"/home/jovyan/private/Agricultural_Field_Boundary/Training_dataset/Cambodia/Prediction_Cambodia_SON_GM_2020Cambodia/Prediction_UNet5/prediction_cambodia_13.tif\"\n",
    "output_directory = \"output_patches\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Open the input raster dataset to get its width and height\n",
    "dataset = gdal.Open(input_file)\n",
    "if dataset is None:\n",
    "    print(\"Failed to open the input raster dataset.\")\n",
    "    exit()\n",
    "\n",
    "width = dataset.RasterXSize\n",
    "height = dataset.RasterYSize\n",
    "\n",
    "# Calculate the number of patches in each dimension\n",
    "num_patches_horizontal = width // patch_width\n",
    "num_patches_vertical = height // patch_height\n",
    "\n",
    "# Create a loop to split the image into patches\n",
    "for i in range(num_patches_vertical):\n",
    "    for j in range(num_patches_horizontal):\n",
    "        patch_name = os.path.join(output_directory, f\"patch_{i}_{j}.tif\")\n",
    "        x_offset = j * patch_width\n",
    "        y_offset = i * patch_height\n",
    "        command = f\"gdal_translate -srcwin {x_offset} {y_offset} {patch_width} {patch_height} -of GTiff {input_file} {patch_name}\"\n",
    "        subprocess.call(command, shell=True)\n",
    "\n",
    "print(\"Patches saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from skimage.segmentation import felzenszwalb\n",
    "from skimage.measure import find_contours\n",
    "from skimage.measure import regionprops\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "# Define the input and output folder paths\n",
    "input_folder = \"/home/jovyan/private/FAO_ParisC/Code/Code_github/output_patches/\"\n",
    "output_folder = \"/home/jovyan/private/FAO_ParisC/Code/Code_github/output_shapefiles/Cambodia_SON\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Iterate over the TIFF files in the input folder\n",
    "tif_files = [f for f in os.listdir(input_folder) if f.endswith(\".tif\")]\n",
    "for tif_file in tif_files:\n",
    "    # Open the grayscale image\n",
    "    tif_path = os.path.join(input_folder, tif_file)\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        grayscale_image = src.read(1)\n",
    "        transform = src.transform\n",
    "\n",
    "    # Perform graph-based segmentation\n",
    "    segments = felzenszwalb(grayscale_image, scale=50, sigma=0.1)\n",
    "\n",
    "    # Create an empty GeoDataFrame for the polygons\n",
    "    polygons_gdf = gpd.GeoDataFrame(columns=['segment_id', 'geometry'])\n",
    "\n",
    "    # Set the maximum segment size threshold\n",
    "    max_segment_size = 1000\n",
    "\n",
    "    # Set the intensity threshold for background segments\n",
    "    background_threshold = 100\n",
    "\n",
    "    # Set the solidity threshold for irregular fragments\n",
    "    solidity_threshold = 0.7\n",
    "\n",
    "    # Iterate over the segments and create polygons\n",
    "    for segment_id in np.unique(segments):\n",
    "        # Create a mask for the current segment\n",
    "        segment_mask = (segments == segment_id)\n",
    "\n",
    "        # Calculate the size of the segment (number of pixels)\n",
    "        segment_size = np.sum(segment_mask)\n",
    "\n",
    "        # Skip segments above the maximum size threshold\n",
    "        if segment_size > max_segment_size:\n",
    "            continue\n",
    "\n",
    "        # Extract the intensity values of the segment\n",
    "        segment_intensities = grayscale_image[segment_mask]\n",
    "\n",
    "        # Check if the segment is predominantly background based on intensity threshold\n",
    "        if np.mean(segment_intensities) < background_threshold:\n",
    "            continue\n",
    "\n",
    "        # Find the contour of the segment mask\n",
    "        contour = find_contours(segment_mask, level=0.5)[0]\n",
    "\n",
    "        # Adjust the contour coordinates to match the image orientation and transformation\n",
    "        contour_coords = []\n",
    "        for coord in contour:\n",
    "            x, y = rasterio.transform.xy(transform, coord[0], coord[1])\n",
    "            contour_coords.append([x, y])\n",
    "\n",
    "        # Create a Polygon from the contour coordinates\n",
    "        polygon = Polygon(contour_coords)\n",
    "\n",
    "        # Calculate the solidity of the segment\n",
    "        props = regionprops(segment_mask.astype(int))[0]\n",
    "        solidity = props.solidity\n",
    "\n",
    "        # Check if the segment has irregular fragments based on solidity threshold\n",
    "        if solidity < solidity_threshold:\n",
    "            continue\n",
    "\n",
    "        # Add polygon to the GeoDataFrame\n",
    "        polygons_gdf = polygons_gdf.append({'segment_id': segment_id, 'geometry': polygon}, ignore_index=True)\n",
    "\n",
    "    # Export polygons as a shapefile\n",
    "    tif_file_name = os.path.splitext(tif_file)[0]\n",
    "    output_shapefile = os.path.join(output_folder, f\"{tif_file_name}.shp\")\n",
    "    polygons_gdf.to_file(output_shapefile)\n",
    "\n",
    "print(\"Polygonization completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "network-prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
